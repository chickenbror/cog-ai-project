{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2ec25e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bison_015', ('black', 'bison')),\n",
       " ('bison_015', ('dusthaze', 'sky')),\n",
       " ('bison_015', ('green', 'field')),\n",
       " ('bison_015', ('rocky', 'mountain')),\n",
       " ('bison_016', ('black', 'bison')),\n",
       " ('bison_016', ('yellow', 'field')),\n",
       " ('bison_016', ('overcast', 'sky')),\n",
       " ('bison_016', ('overcast', 'sky')),\n",
       " ('bison_021', ('black', 'bison')),\n",
       " ('bison_021', ('blue', 'sky')),\n",
       " ('bison_021', ('green', 'field')),\n",
       " ('bison_022', ('black', 'bison')),\n",
       " ('bison_022', ('blue', 'sky')),\n",
       " ('bison_022', ('snowy', 'field')),\n",
       " ('bison_023', ('black', 'bison')),\n",
       " ('bison_023', ('snowy', 'field')),\n",
       " ('bison_023', ('blue', 'sky')),\n",
       " ('bison_023', ('snowy', 'field')),\n",
       " ('bison_025', ('black', 'bison')),\n",
       " ('bison_025', ('yellow', 'field')),\n",
       " ('bison_025', ('yellow', 'field')),\n",
       " ('bison_025', ('dusthaze', 'sky')),\n",
       " ('bison_026', ('black', 'bison')),\n",
       " ('bison_026', ('yellow', 'field')),\n",
       " ('bison_026', ('dusthaze', 'sky')),\n",
       " ('bison_026', ('yellow', 'field')),\n",
       " ('bison_029', ('black', 'bison')),\n",
       " ('bison_029', ('yellow', 'field')),\n",
       " ('bison_029', ('dusthaze', 'sky')),\n",
       " ('bison_030', ('black', 'bison')),\n",
       " ('bison_030', ('yellow', 'field')),\n",
       " ('bison_030', ('yellow', 'field')),\n",
       " ('bison_031', ('black', 'bison')),\n",
       " ('bison_031', ('green', 'field')),\n",
       " ('bison_031', ('green', 'field')),\n",
       " ('bison_031', ('green', 'field')),\n",
       " ('bison_034', ('black', 'bison')),\n",
       " ('bison_034', ('green', 'field')),\n",
       " ('bison_034', ('green', 'field')),\n",
       " ('bison_037', ('black', 'bison')),\n",
       " ('bison_037', ('blue', 'sky')),\n",
       " ('bison_037', ('green', 'field')),\n",
       " ('bison_038', ('black', 'bison')),\n",
       " ('bison_038', ('snowy', 'field')),\n",
       " ('bison_038', ('-', 'tree')),\n",
       " ('bison_040', ('black', 'bison')),\n",
       " ('bison_040', ('-', 'sand')),\n",
       " ('bison_040', ('blue', 'sky')),\n",
       " ('bison_041', ('black', 'bison')),\n",
       " ('bison_041', ('yellow', 'field')),\n",
       " ('bison_041', ('yellow', 'field')),\n",
       " ('bison_045', ('black', 'bison')),\n",
       " ('bison_045', ('blue', 'sky')),\n",
       " ('bison_045', ('green', 'field')),\n",
       " ('bison_048', ('black', 'bison')),\n",
       " ('bison_048', ('snowy', 'field')),\n",
       " ('bison_048', ('snowy', 'field')),\n",
       " ('bison_0481', ('black', 'bison')),\n",
       " ('bison_0481', ('snowy', 'field')),\n",
       " ('bison_0481', ('snowy', 'field')),\n",
       " ('bison_049', ('black', 'bison')),\n",
       " ('bison_053', ('black', 'bison')),\n",
       " ('bison_053', ('rocky', 'mountain')),\n",
       " ('bison_053', ('green', 'field')),\n",
       " ('bison_053', ('green', 'field')),\n",
       " ('bison_053', ('blue', 'sky')),\n",
       " ('bison_056', ('black', 'bison')),\n",
       " ('bison_056', ('yellow', 'field')),\n",
       " ('bison_056', ('yellow', 'field')),\n",
       " ('bison_058', ('black', 'bison')),\n",
       " ('bison_058', ('yellow', 'field')),\n",
       " ('bison_058', ('blue', 'sky')),\n",
       " ('bison_058', ('blue', 'sky')),\n",
       " ('bison_0581', ('black', 'bison')),\n",
       " ('bison_0581', ('yellow', 'field')),\n",
       " ('bison_0581', ('blue', 'sky')),\n",
       " ('bison_060', ('black', 'bison')),\n",
       " ('bison_060', ('green', 'field')),\n",
       " ('cliff_001', ('black', 'cliff')),\n",
       " ('cliff_001', ('blue', 'sky')),\n",
       " ('cliff_001', ('blue', 'ocean')),\n",
       " ('cliff_003', ('black', 'cliff')),\n",
       " ('cliff_003', ('dusthaze', 'sky')),\n",
       " ('cliff_003', ('blue', 'ocean')),\n",
       " ('elephant_020', ('-', 'elephant')),\n",
       " ('elephant_020', ('yellow', 'field')),\n",
       " ('elephant_021', ('-', 'elephant')),\n",
       " ('elephant_021', ('green', 'field')),\n",
       " ('elephant_021', ('rocky', 'mountain')),\n",
       " ('elephant_026', ('-', 'elephant')),\n",
       " ('elephant_026', ('green', 'field')),\n",
       " ('elephant_026', ('cloudy', 'sky')),\n",
       " ('elephant_027', ('-', 'elephant')),\n",
       " ('elephant_027', ('green', 'field')),\n",
       " ('elephant_027', ('dusthaze', 'sky')),\n",
       " ('elephant_027', ('dusthaze', 'sky')),\n",
       " ('elephant_028', ('-', 'elephant')),\n",
       " ('elephant_028', ('dusthaze', 'sky')),\n",
       " ('elephant_028', ('dusthaze', 'sky')),\n",
       " ('elephant_028', ('green', 'field')),\n",
       " ('elephant_029', ('-', 'elephant')),\n",
       " ('elephant_029', ('yellow', 'field')),\n",
       " ('elephant_030', ('-', 'elephant')),\n",
       " ('elephant_030', ('yellow', 'field')),\n",
       " ('elephant_030', ('dusthaze', 'sky')),\n",
       " ('elephant_030', ('dusthaze', 'sky')),\n",
       " ('elephant_032', ('blue', 'sky')),\n",
       " ('elephant_032', ('blue', 'sky')),\n",
       " ('elephant_032', ('-', 'elephant')),\n",
       " ('elephant_032', ('green', 'field')),\n",
       " ('elephant_037', ('-', 'elephant')),\n",
       " ('elephant_037', ('green', 'field')),\n",
       " ('elephant_037', ('blue', 'sky')),\n",
       " ('elephant_039', ('-', 'elephant')),\n",
       " ('elephant_039', ('green', 'field')),\n",
       " ('elephant_039', ('green', 'field')),\n",
       " ('elephant_039', ('dusthaze', 'sky')),\n",
       " ('elephant_046', ('-', 'elephant')),\n",
       " ('elephant_046', ('yellow', 'field')),\n",
       " ('elephant_046', ('blue', 'sky')),\n",
       " ('elephant_046', ('blue', 'sky')),\n",
       " ('elephant_047', ('-', 'elephant')),\n",
       " ('elephant_047', ('green', 'field')),\n",
       " ('elephant_047', ('overcast', 'sky')),\n",
       " ('elephant_047', ('overcast', 'sky')),\n",
       " ('elephant_0481', ('-', 'elephant')),\n",
       " ('elephant_0481', ('green', 'field')),\n",
       " ('elephant_0481', ('overcast', 'sky')),\n",
       " ('elephant_051', ('-', 'elephant')),\n",
       " ('elephant_051', ('yellow', 'field')),\n",
       " ('elephant_051', ('dusthaze', 'sky')),\n",
       " ('elephant_052', ('-', 'elephant')),\n",
       " ('elephant_052', ('yellow', 'field')),\n",
       " ('elephant_052', ('-', 'tree')),\n",
       " ('elephant_052', ('blue', 'sky')),\n",
       " ('elephant_054', ('overcast', 'sky')),\n",
       " ('elephant_054', ('-', 'elephant')),\n",
       " ('elephant_054', ('green', 'field')),\n",
       " ('elephant_062', ('-', 'elephant')),\n",
       " ('elephant_062', ('blue', 'ocean')),\n",
       " ('elephant_062', ('-', 'tree')),\n",
       " ('elephant_062', ('blue', 'ocean')),\n",
       " ('elephant_064', ('-', 'elephant')),\n",
       " ('elephant_069', ('-', 'elephant')),\n",
       " ('elephant_069', ('green', 'field')),\n",
       " ('elephant_069', ('dusthaze', 'sky')),\n",
       " ('elephant_070', ('-', 'elephant')),\n",
       " ('elephant_070', ('green', 'field')),\n",
       " ('elephant_070', ('dusthaze', 'sky')),\n",
       " ('elephant_071', ('-', 'elephant')),\n",
       " ('elephant_071', ('green', 'field')),\n",
       " ('elephant_078', ('-', 'elephant')),\n",
       " ('elephant_078', ('green', 'field')),\n",
       " ('elephant_078', ('overcast', 'sky')),\n",
       " ('elephant_079', ('-', 'elephant')),\n",
       " ('elephant_079', ('green', 'field')),\n",
       " ('elephant_079', ('blue', 'sky')),\n",
       " ('elephant_079', ('blue', 'sky')),\n",
       " ('elephant_082', ('-', 'elephant')),\n",
       " ('elephant_082', ('yellow', 'field')),\n",
       " ('elephant_082', ('overcast', 'sky')),\n",
       " ('elephant_082', ('overcast', 'sky')),\n",
       " ('elephant_083', ('-', 'elephant')),\n",
       " ('elephant_083', ('green', 'field')),\n",
       " ('elephant_083', ('cloudy', 'sky')),\n",
       " ('elephant_083', ('cloudy', 'sky')),\n",
       " ('field18', ('red', 'flower')),\n",
       " ('field18', ('dusthaze', 'sky')),\n",
       " ('highway_art1204', ('overcast', 'sky')),\n",
       " ('highway_art1204', ('-', 'road')),\n",
       " ('highway_art1673', ('-', 'road')),\n",
       " ('highway_art1673', ('cloudy', 'sky')),\n",
       " ('highway_art1682', ('cloudy', 'sky')),\n",
       " ('highway_art1682', ('-', 'tree')),\n",
       " ('highway_art1682', ('-', 'road')),\n",
       " ('highway_bost147', ('blue', 'sky')),\n",
       " ('highway_bost147', ('-', 'road')),\n",
       " ('highway_bost150', ('blue', 'sky')),\n",
       " ('highway_bost150', ('-', 'road')),\n",
       " ('highway_bost150', ('-', 'tree')),\n",
       " ('highway_bost151', ('blue', 'sky')),\n",
       " ('highway_bost151', ('-', 'road')),\n",
       " ('highway_bost151', ('-', 'tree')),\n",
       " ('highway_bost153', ('-', 'tree')),\n",
       " ('highway_bost153', ('blue', 'sky')),\n",
       " ('highway_bost153', ('-', 'tree')),\n",
       " ('highway_bost153', ('-', 'road')),\n",
       " ('highway_bost164', ('blue', 'sky')),\n",
       " ('highway_bost164', ('-', 'tree')),\n",
       " ('highway_bost164', ('-', 'road')),\n",
       " ('highway_bost165', ('blue', 'sky')),\n",
       " ('highway_bost165', ('-', 'tree')),\n",
       " ('highway_bost165', ('-', 'tree')),\n",
       " ('highway_bost165', ('-', 'road')),\n",
       " ('highway_bost166', ('blue', 'sky')),\n",
       " ('highway_bost166', ('-', 'tree')),\n",
       " ('highway_bost166', ('-', 'tree')),\n",
       " ('highway_bost166', ('-', 'road')),\n",
       " ('highway_bost167', ('blue', 'sky')),\n",
       " ('highway_bost167', ('-', 'tree')),\n",
       " ('highway_bost167', ('-', 'tree')),\n",
       " ('highway_bost167', ('-', 'road')),\n",
       " ('highway_bost170', ('blue', 'sky')),\n",
       " ('highway_bost170', ('-', 'tree')),\n",
       " ('highway_bost170', ('-', 'tree')),\n",
       " ('highway_bost170', ('-', 'road')),\n",
       " ('highway_bost171', ('blue', 'sky')),\n",
       " ('highway_bost171', ('-', 'tree')),\n",
       " ('highway_bost171', ('-', 'tree')),\n",
       " ('highway_bost171', ('-', 'road')),\n",
       " ('highway_bost173', ('-', 'tree')),\n",
       " ('highway_bost173', ('blue', 'sky')),\n",
       " ('highway_bost173', ('-', 'road')),\n",
       " ('highway_bost174', ('blue', 'sky')),\n",
       " ('highway_bost174', ('-', 'tree')),\n",
       " ('highway_bost174', ('-', 'tree')),\n",
       " ('highway_bost174', ('-', 'road')),\n",
       " ('highway_bost177', ('cloudy', 'sky')),\n",
       " ('highway_bost177', ('-', 'tree')),\n",
       " ('highway_bost177', ('-', 'tree')),\n",
       " ('highway_bost177', ('-', 'road')),\n",
       " ('highway_bost178', ('cloudy', 'sky')),\n",
       " ('highway_bost178', ('-', 'road')),\n",
       " ('highway_bost180', ('cloudy', 'sky')),\n",
       " ('highway_bost180', ('-', 'road')),\n",
       " ('highway_bost181', ('cloudy', 'sky')),\n",
       " ('highway_bost181', ('-', 'tree')),\n",
       " ('highway_bost181', ('-', 'road')),\n",
       " ('highway_bost183', ('cloudy', 'sky')),\n",
       " ('highway_bost183', ('-', 'tree')),\n",
       " ('highway_bost183', ('-', 'tree')),\n",
       " ('highway_bost183', ('-', 'road')),\n",
       " ('highway_bost290', ('cloudy', 'sky')),\n",
       " ('highway_bost290', ('-', 'tree')),\n",
       " ('highway_bost290', ('-', 'road')),\n",
       " ('highway_bost292', ('blue', 'sky')),\n",
       " ('highway_bost292', ('-', 'road')),\n",
       " ('highway_bost301', ('blue', 'sky')),\n",
       " ('highway_bost301', ('-', 'tree')),\n",
       " ('highway_bost301', ('-', 'road')),\n",
       " ('highway_bost302', ('blue', 'sky')),\n",
       " ('highway_bost302', ('-', 'road')),\n",
       " ('highway_bost306', ('blue', 'sky')),\n",
       " ('highway_bost306', ('-', 'tree')),\n",
       " ('highway_bost306', ('-', 'road')),\n",
       " ('highway_bost322', ('cloudy', 'sky')),\n",
       " ('highway_bost322', ('-', 'tree')),\n",
       " ('highway_bost322', ('-', 'road')),\n",
       " ('highway_bost323', ('cloudy', 'sky')),\n",
       " ('highway_bost323', ('-', 'tree')),\n",
       " ('highway_bost323', ('-', 'tree')),\n",
       " ('highway_bost323', ('-', 'road')),\n",
       " ('highway_bost325', ('cloudy', 'sky')),\n",
       " ('highway_bost325', ('-', 'tree')),\n",
       " ('highway_bost325', ('-', 'road')),\n",
       " ('highway_bost330', ('cloudy', 'sky')),\n",
       " ('highway_bost330', ('-', 'tree')),\n",
       " ('highway_bost330', ('-', 'road')),\n",
       " ('highway_bost332', ('cloudy', 'sky')),\n",
       " ('highway_bost332', ('-', 'tree')),\n",
       " ('highway_bost332', ('-', 'road')),\n",
       " ('highway_bost335', ('blue', 'sky')),\n",
       " ('highway_bost335', ('-', 'tree')),\n",
       " ('highway_bost335', ('-', 'road')),\n",
       " ('highway_bost389', ('cloudy', 'sky')),\n",
       " ('highway_bost389', ('-', 'tree')),\n",
       " ('highway_bost389', ('-', 'road')),\n",
       " ('highway_bost403', ('overcast', 'sky')),\n",
       " ('highway_bost403', ('green', 'field')),\n",
       " ('highway_bost403', ('-', 'road')),\n",
       " ('highway_gre400', ('overcast', 'sky')),\n",
       " ('highway_gre400', ('-', 'road')),\n",
       " ('highway_gre403', ('-', 'road')),\n",
       " ('highway_gre403', ('overcast', 'sky')),\n",
       " ('highway_gre414', ('blue', 'sky')),\n",
       " ('highway_gre414', ('-', 'road')),\n",
       " ('highway_gre414', ('rocky', 'mountain')),\n",
       " ('highway_gre426', ('overcast', 'sky')),\n",
       " ('highway_gre426', ('rocky', 'mountain')),\n",
       " ('highway_gre426', ('-', 'road')),\n",
       " ('highway_gre459', ('blue', 'sky')),\n",
       " ('highway_gre459', ('rocky', 'mountain')),\n",
       " ('highway_gre459', ('-', 'road')),\n",
       " ('highway_gre46', ('-', 'road')),\n",
       " ('highway_gre46', ('dusthaze', 'sky')),\n",
       " ('highway_gre473', ('-', 'road')),\n",
       " ('highway_gre473', ('overcast', 'sky')),\n",
       " ('highway_gre474', ('-', 'road')),\n",
       " ('highway_gre474', ('overcast', 'sky')),\n",
       " ('highway_gre475', ('-', 'tree')),\n",
       " ('highway_gre475', ('-', 'road')),\n",
       " ('highway_gre475', ('overcast', 'sky')),\n",
       " ('highway_gre484', ('-', 'tree')),\n",
       " ('highway_gre484', ('-', 'tree')),\n",
       " ('highway_gre484', ('-', 'road')),\n",
       " ('highway_gre484', ('overcast', 'sky')),\n",
       " ('highway_gre493', ('overcast', 'sky')),\n",
       " ('highway_gre493', ('rocky', 'mountain')),\n",
       " ('highway_gre493', ('-', 'road')),\n",
       " ('highway_gre532', ('overcast', 'sky')),\n",
       " ('highway_gre532', ('rocky', 'mountain')),\n",
       " ('highway_gre532', ('-', 'road')),\n",
       " ('highway_gre657', ('dusthaze', 'sky')),\n",
       " ('highway_gre657', ('-', 'road')),\n",
       " ('highway_gre658', ('-', 'road')),\n",
       " ('highway_gre658', ('perspective', 'building')),\n",
       " ('highway_gre658', ('overcast', 'sky')),\n",
       " ('highway_gre662', ('dusthaze', 'sky')),\n",
       " ('highway_gre662', ('-', 'road')),\n",
       " ('highway_land463', ('-', 'road')),\n",
       " ('highway_land463', ('overcast', 'sky')),\n",
       " ('highway_n480023', ('blue', 'sky')),\n",
       " ('highway_n480023', ('-', 'tree')),\n",
       " ('highway_n480023', ('-', 'tree')),\n",
       " ('highway_n480023', ('-', 'road')),\n",
       " ('horse_030', ('white', 'horse')),\n",
       " ('horse_030', ('-', 'tree')),\n",
       " ('horse_030', ('green', 'field')),\n",
       " ('horse_034', ('green', 'field')),\n",
       " ('horse_034', ('-', 'tree')),\n",
       " ('horse_034', ('white', 'horse')),\n",
       " ('horse_037', ('green', 'field')),\n",
       " ('horse_037', ('brown', 'horse')),\n",
       " ('horse_037', ('dusthaze', 'sky')),\n",
       " ('horse_040', ('brown', 'horse')),\n",
       " ('horse_040', ('snowy', 'field')),\n",
       " ('horse_040', ('dusthaze', 'sky')),\n",
       " ('horse_046', ('white', 'horse')),\n",
       " ('horse_046', ('green', 'field')),\n",
       " ('horse_046', ('green', 'field')),\n",
       " ('horse_046', ('dusthaze', 'sky')),\n",
       " ('horse_049', ('brown', 'horse')),\n",
       " ('horse_049', ('green', 'field')),\n",
       " ('horse_049', ('green', 'field')),\n",
       " ('horse_049', ('green', 'field')),\n",
       " ('horse_052', ('brown', 'horse')),\n",
       " ('horse_052', ('green', 'field')),\n",
       " ('horse_052', ('yellow', 'field')),\n",
       " ('horse_057', ('brown', 'horse')),\n",
       " ('horse_057', ('green', 'field')),\n",
       " ('horse_057', ('-', 'tree')),\n",
       " ('horse_059', ('brown', 'horse')),\n",
       " ('horse_059', ('yellow', 'field')),\n",
       " ('horse_061', ('brown', 'horse')),\n",
       " ('horse_061', ('green', 'field')),\n",
       " ('horse_061', ('-', 'tree')),\n",
       " ('horse_065', ('brown', 'horse')),\n",
       " ('horse_065', ('overcast', 'sky')),\n",
       " ('horse_065', ('green', 'field')),\n",
       " ('horse_067', ('brown', 'horse')),\n",
       " ('horse_067', ('green', 'field')),\n",
       " ('horse_067', ('blue', 'sky')),\n",
       " ('horse_069', ('white', 'horse')),\n",
       " ('horse_069', ('green', 'field')),\n",
       " ('horse_069', ('-', 'tree')),\n",
       " ('horse_070', ('brown', 'horse')),\n",
       " ('horse_070', ('yellow', 'field')),\n",
       " ('horse_070', ('blue', 'sky')),\n",
       " ('horse_078', ('white', 'horse')),\n",
       " ('horse_078', ('-', 'tree')),\n",
       " ('horse_078', ('blue', 'sky')),\n",
       " ('horse_078', ('green', 'field')),\n",
       " ('horse_079', ('-', 'tree')),\n",
       " ('horse_079', ('green', 'field')),\n",
       " ('horse_079', ('white', 'horse')),\n",
       " ('horse_083', ('white', 'horse')),\n",
       " ('horse_083', ('green', 'field')),\n",
       " ('horse_083', ('blue', 'sky')),\n",
       " ('horse_085', ('brown', 'horse')),\n",
       " ('horse_085', ('dusthaze', 'sky')),\n",
       " ('horse_085', ('yellow', 'field')),\n",
       " ('horse_087', ('white', 'horse')),\n",
       " ('horse_087', ('green', 'field')),\n",
       " ('horse_087', ('green', 'field')),\n",
       " ('horse_090', ('brown', 'horse')),\n",
       " ('horse_090', ('green', 'field')),\n",
       " ('horse_090', ('green', 'field')),\n",
       " ('horse_090', ('green', 'field')),\n",
       " ('horse_091', ('brown', 'horse')),\n",
       " ('horse_091', ('green', 'field')),\n",
       " ('horse_091', ('-', 'tree')),\n",
       " ('horse_091', ('dusthaze', 'sky')),\n",
       " ('horse_093', ('brown', 'horse')),\n",
       " ('horse_093', ('green', 'field')),\n",
       " ('horse_093', ('overcast', 'sky')),\n",
       " ('horse_094', ('brown', 'horse')),\n",
       " ('horse_094', ('green', 'field')),\n",
       " ('horse_094', ('dusthaze', 'sky')),\n",
       " ('horse_095', ('brown', 'horse')),\n",
       " ('horse_095', ('green', 'field')),\n",
       " ('horse_095', ('blue', 'sky')),\n",
       " ('horse_096', ('blue', 'sky')),\n",
       " ('horse_096', ('brown', 'horse')),\n",
       " ('horse_096', ('green', 'field')),\n",
       " ('horse_099', ('blue', 'sky')),\n",
       " ('horse_099', ('white', 'horse')),\n",
       " ('horse_099', ('yellow', 'field')),\n",
       " ('horse_099', ('yellow', 'field')),\n",
       " ('horse_101', ('green', 'field')),\n",
       " ('horse_101', ('green', 'field')),\n",
       " ('horse_101', ('brown', 'horse')),\n",
       " ('horse_107', ('brown', 'horse')),\n",
       " ('horse_107', ('green', 'field')),\n",
       " ('horse_107', ('dusthaze', 'sky')),\n",
       " ('horse_108', ('brown', 'horse')),\n",
       " ('horse_108', ('green', 'field')),\n",
       " ('horse_108', ('-', 'tree')),\n",
       " ('horse_109', ('white', 'horse')),\n",
       " ('horse_109', ('-', 'tree')),\n",
       " ('horse_110', ('brown', 'horse')),\n",
       " ('horse_110', ('green', 'field')),\n",
       " ('horse_110', ('green', 'field')),\n",
       " ('horse_113', ('brown', 'horse')),\n",
       " ('horse_113', ('green', 'field')),\n",
       " ('horse_113', ('-', 'tree')),\n",
       " ('horse_115', ('brown', 'horse')),\n",
       " ('horse_115', ('green', 'field')),\n",
       " ('horse_115', ('dusthaze', 'sky')),\n",
       " ('horse_116', ('overcast', 'sky')),\n",
       " ('horse_116', ('brown', 'horse')),\n",
       " ('horse_116', ('yellow', 'field')),\n",
       " ('horse_120', ('overcast', 'sky')),\n",
       " ('horse_120', ('brown', 'horse')),\n",
       " ('horse_120', ('overcast', 'sky')),\n",
       " ('horse_120', ('green', 'field')),\n",
       " ('horse_122', ('green', 'field')),\n",
       " ('horse_122', ('-', 'tree')),\n",
       " ('horse_122', ('-', 'tree')),\n",
       " ('horse_122', ('brown', 'horse')),\n",
       " ('horse_125', ('dusthaze', 'sky')),\n",
       " ('horse_125', ('green', 'field')),\n",
       " ('horse_125', ('brown', 'horse')),\n",
       " ('horse_130', ('white', 'horse')),\n",
       " ('horse_130', ('overcast', 'sky')),\n",
       " ('horse_130', ('green', 'field')),\n",
       " ('horse_131', ('green', 'field')),\n",
       " ('horse_131', ('green', 'field')),\n",
       " ('horse_131', ('green', 'field')),\n",
       " ('horse_131', ('white', 'horse')),\n",
       " ('horse_133', ('white', 'horse')),\n",
       " ('horse_133', ('blue', 'sky')),\n",
       " ('horse_133', ('blue', 'sky')),\n",
       " ('horse_133', ('blue', 'sky')),\n",
       " ('horse_133', ('-', 'sand')),\n",
       " ('horse_134', ('white', 'horse')),\n",
       " ('horse_134', ('green', 'field')),\n",
       " ('horse_134', ('green', 'field')),\n",
       " ('horse_135', ('brown', 'horse')),\n",
       " ('horse_135', ('-', 'sand')),\n",
       " ('horse_138', ('-', 'tree')),\n",
       " ('horse_138', ('white', 'horse')),\n",
       " ('horse_138', ('-', 'road')),\n",
       " ('horse_143', ('brown', 'horse')),\n",
       " ('horse_143', ('green', 'field')),\n",
       " ('horse_143', ('dusthaze', 'sky')),\n",
       " ('horse_147', ('blue', 'sky')),\n",
       " ('horse_147', ('green', 'field')),\n",
       " ('horse_147', ('brown', 'horse')),\n",
       " ('horse_148', ('brown', 'horse')),\n",
       " ('horse_148', ('green', 'field')),\n",
       " ('horse_148', ('green', 'field')),\n",
       " ('horse_148', ('dusthaze', 'sky')),\n",
       " ('horse_154', ('brown', 'horse')),\n",
       " ('horse_154', ('green', 'field')),\n",
       " ('ibis_002', ('black', 'ibis')),\n",
       " ('ibis_003', ('black', 'ibis')),\n",
       " ('ibis_003', ('green', 'field')),\n",
       " ('ibis_003', ('green', 'field')),\n",
       " ('ibis_007', ('white', 'ibis')),\n",
       " ('ibis_007', ('green', 'field')),\n",
       " ('ibis_007', ('green', 'field')),\n",
       " ('ibis_009', ('scarlet', 'ibis')),\n",
       " ('ibis_011', ('scarlet', 'ibis')),\n",
       " ('ibis_011', ('yellow', 'field')),\n",
       " ('ibis_013', ('scarlet', 'ibis')),\n",
       " ('ibis_015', ('scarlet', 'ibis')),\n",
       " ('ibis_015', ('yellow', 'field')),\n",
       " ('ibis_016', ('scarlet', 'ibis')),\n",
       " ('ibis_021', ('black', 'ibis')),\n",
       " ('ibis_023', ('scarlet', 'ibis')),\n",
       " ('ibis_023', ('green', 'field')),\n",
       " ('ibis_023', ('green', 'field')),\n",
       " ('ibis_027', ('scarlet', 'ibis')),\n",
       " ('ibis_027', ('green', 'field')),\n",
       " ('ibis_027', ('green', 'field')),\n",
       " ('ibis_031', ('black', 'ibis')),\n",
       " ('ibis_031', ('green', 'field')),\n",
       " ('ibis_031', ('green', 'field')),\n",
       " ('ibis_032', ('black', 'ibis')),\n",
       " ('ibis_032', ('green', 'field')),\n",
       " ('ibis_032', ('green', 'field')),\n",
       " ('ibis_032', ('green', 'field')),\n",
       " ('ibis_039', ('scarlet', 'ibis')),\n",
       " ('ibis_040', ('scarlet', 'ibis')),\n",
       " ('ibis_046', ('white', 'ibis')),\n",
       " ('ibis_046', ('yellow', 'field')),\n",
       " ('ibis_050', ('scarlet', 'ibis')),\n",
       " ('ibis_050', ('dusthaze', 'sky')),\n",
       " ('ibis_054', ('scarlet', 'ibis')),\n",
       " ('ibis_054', ('green', 'field')),\n",
       " ('ibis_054', ('green', 'field')),\n",
       " ('ibis_055', ('white', 'ibis')),\n",
       " ('ibis_055', ('green', 'field')),\n",
       " ('ibis_055', ('green', 'field')),\n",
       " ('ibis_058', ('green', 'field')),\n",
       " ('ibis_058', ('scarlet', 'ibis')),\n",
       " ('ibis_062', ('scarlet', 'ibis')),\n",
       " ('ibis_063', ('scarlet', 'ibis')),\n",
       " ('ibis_067', ('scarlet', 'ibis')),\n",
       " ('ibis_067', ('-', 'tree')),\n",
       " ('ibis_068', ('black', 'ibis')),\n",
       " ('ibis_068', ('yellow', 'field')),\n",
       " ('ibis_068', ('yellow', 'field')),\n",
       " ('ibis_069', ('black', 'ibis')),\n",
       " ('ibis_069', ('green', 'field')),\n",
       " ('ibis_069', ('green', 'field')),\n",
       " ('ibis_070', ('black', 'ibis')),\n",
       " ('ibis_070', ('yellow', 'field')),\n",
       " ('ibis_070', ('yellow', 'field')),\n",
       " ('ibis_070', ('yellow', 'field')),\n",
       " ('ibis_071', ('black', 'ibis')),\n",
       " ('ibis_071', ('green', 'field')),\n",
       " ('ibis_071', ('green', 'field')),\n",
       " ('ibis_072', ('green', 'field')),\n",
       " ('ibis_072', ('black', 'ibis')),\n",
       " ('ibis_078', ('scarlet', 'ibis')),\n",
       " ('ibis_079', ('scarlet', 'ibis')),\n",
       " ('ibis_080', ('scarlet', 'ibis')),\n",
       " ('ibis_084', ('scarlet', 'ibis')),\n",
       " ('ibis_084', ('green', 'field')),\n",
       " ('ibis_084', ('green', 'field')),\n",
       " ('ibis_087', ('black', 'ibis')),\n",
       " ('ibis_087', ('blue', 'sky')),\n",
       " ('ibis_087', ('blue', 'sky')),\n",
       " ('ibis_090', ('scarlet', 'ibis')),\n",
       " ('ibis_090', ('green', 'field')),\n",
       " ('ibis_090', ('green', 'field')),\n",
       " ('ibis_090', ('green', 'field')),\n",
       " ('ibis_091', ('white', 'ibis')),\n",
       " ('ibis_091', ('green', 'field')),\n",
       " ('ibis_091', ('green', 'field')),\n",
       " ('ibis_092', ('white', 'ibis')),\n",
       " ('ibis_092', ('green', 'field')),\n",
       " ('ibis_092', ('green', 'field')),\n",
       " ('ibis_094', ('black', 'ibis')),\n",
       " ('ibis_094', ('green', 'field')),\n",
       " ('ibis_094', ('green', 'field')),\n",
       " ('ibis_095', ('black', 'ibis')),\n",
       " ('ibis_095', ('green', 'field')),\n",
       " ('ibis_095', ('green', 'field')),\n",
       " ('ibis_097', ('black', 'ibis')),\n",
       " ('ibis_097', ('green', 'field')),\n",
       " ('ibis_102', ('black', 'ibis')),\n",
       " ('ibis_105', ('scarlet', 'ibis')),\n",
       " ('ibis_105', ('-', 'tree')),\n",
       " ('ibis_105', ('-', 'tree')),\n",
       " ('ibis_105', ('-', 'tree')),\n",
       " ('ibis_106', ('black', 'ibis')),\n",
       " ('ibis_109', ('white', 'ibis')),\n",
       " ('ibis_110', ('black', 'ibis')),\n",
       " ('ibis_110', ('yellow', 'field')),\n",
       " ('ibis_114', ('scarlet', 'ibis')),\n",
       " ('ibis_117', ('scarlet', 'ibis')),\n",
       " ('ibis_118', ('yellow', 'field')),\n",
       " ('ibis_118', ('black', 'ibis')),\n",
       " ('ibis_119', ('black', 'ibis')),\n",
       " ('ibis_119', ('green', 'field')),\n",
       " ('ibis_120', ('white', 'ibis')),\n",
       " ('ibis_120', ('green', 'field')),\n",
       " ('ibis_120', ('overcast', 'sky')),\n",
       " ('ibis_121', ('white', 'ibis')),\n",
       " ('ibis_121', ('green', 'field')),\n",
       " ('ibis_122', ('white', 'ibis')),\n",
       " ('ibis_122', ('overcast', 'sky')),\n",
       " ('ibis_122', ('green', 'field')),\n",
       " ('ibis_123', ('white', 'ibis')),\n",
       " ('ibis_124', ('white', 'ibis')),\n",
       " ('ibis_125', ('white', 'ibis')),\n",
       " ('ibis_125', ('blue', 'ocean')),\n",
       " ('ibis_127', ('white', 'ibis')),\n",
       " ('ibis_128', ('white', 'ibis')),\n",
       " ('ibis_128', ('blue', 'ocean')),\n",
       " ('ibis_129', ('white', 'ibis')),\n",
       " ('ibis_129', ('yellow', 'field')),\n",
       " ('ibis_130', ('white', 'ibis')),\n",
       " ('ibis_133', ('white', 'ibis')),\n",
       " ('ibis_140', ('white', 'ibis')),\n",
       " ('ibis_140', ('green', 'field')),\n",
       " ('ibis_140', ('green', 'field')),\n",
       " ('ibis_141', ('white', 'ibis')),\n",
       " ('ibis_141', ('blue', 'ocean')),\n",
       " ('ibis_143', ('white', 'ibis')),\n",
       " ('ibis_143', ('green', 'field')),\n",
       " ('ibis_143', ('green', 'field')),\n",
       " ('ibis_147', ('white', 'ibis')),\n",
       " ('ibis_147', ('blue', 'ocean')),\n",
       " ('ibis_149', ('white', 'ibis')),\n",
       " ('ibis_149', ('blue', 'ocean')),\n",
       " ('ibis_150', ('white', 'ibis')),\n",
       " ('mountain_003', ('blue', 'sky')),\n",
       " ('mountain_003', ('snowy', 'mountain')),\n",
       " ('mountain_004', ('blue', 'sky')),\n",
       " ('mountain_004', ('rocky', 'mountain')),\n",
       " ('mountain_0041', ('cloudy', 'sky')),\n",
       " ('mountain_0041', ('rocky', 'mountain')),\n",
       " ('mountain_005', ('rocky', 'mountain')),\n",
       " ('mountain_005', ('blue', 'sky')),\n",
       " ('mountain_006', ('overcast', 'sky')),\n",
       " ('mountain_006', ('snowy', 'mountain')),\n",
       " ('mountain_007', ('blue', 'sky')),\n",
       " ('mountain_007', ('rocky', 'mountain')),\n",
       " ('mountain_009', ('cloudy', 'sky')),\n",
       " ('mountain_009', ('rocky', 'mountain')),\n",
       " ('mountain_009', ('green', 'field')),\n",
       " ('mountain_010', ('blue', 'sky')),\n",
       " ('mountain_010', ('snowy', 'mountain')),\n",
       " ('mountain_011', ('rocky', 'mountain')),\n",
       " ('mountain_011', ('blue', 'sky')),\n",
       " ('mountain_012', ('blue', 'sky')),\n",
       " ('mountain_012', ('rocky', 'mountain')),\n",
       " ('mountain_014', ('cloudy', 'sky')),\n",
       " ('mountain_014', ('rocky', 'mountain')),\n",
       " ('mountain_014', ('-', 'tree')),\n",
       " ('mountain_016', ('snowy', 'mountain')),\n",
       " ('mountain_016', ('blue', 'sky')),\n",
       " ('mountain_017', ('blue', 'sky')),\n",
       " ('mountain_017', ('rocky', 'mountain')),\n",
       " ('mountain_017', ('-', 'tree')),\n",
       " ('mountain_018', ('overcast', 'sky')),\n",
       " ('mountain_018', ('overcast', 'sky')),\n",
       " ('mountain_018', ('snowy', 'mountain')),\n",
       " ('mountain_021', ('snowy', 'mountain')),\n",
       " ('mountain_021', ('blue', 'sky')),\n",
       " ('mountain_022', ('overcast', 'sky')),\n",
       " ('mountain_022', ('snowy', 'mountain')),\n",
       " ('mountain_024', ('-', 'tree')),\n",
       " ('mountain_024', ('blue', 'sky')),\n",
       " ('mountain_024', ('snowy', 'mountain')),\n",
       " ('mountain_026', ('snowy', 'mountain')),\n",
       " ('mountain_026', ('overcast', 'sky')),\n",
       " ('mountain_0261', ('snowy', 'mountain')),\n",
       " ('mountain_0261', ('green', 'field')),\n",
       " ('mountain_0271', ('blue', 'ocean')),\n",
       " ('mountain_0271', ('snowy', 'mountain')),\n",
       " ('mountain_0271', ('blue', 'sky')),\n",
       " ('mountain_036', ('blue', 'sky')),\n",
       " ('mountain_036', ('rocky', 'mountain')),\n",
       " ('mountain_039', ('blue', 'sky')),\n",
       " ('mountain_039', ('rocky', 'mountain')),\n",
       " ('mountain_040', ('overcast', 'sky')),\n",
       " ('mountain_040', ('snowy', 'mountain')),\n",
       " ('mountain_042', ('overcast', 'sky')),\n",
       " ('mountain_042', ('snowy', 'mountain')),\n",
       " ('mountain_049', ('overcast', 'sky')),\n",
       " ('mountain_049', ('rocky', 'mountain')),\n",
       " ('mountain_054', ('blue', 'sky')),\n",
       " ('mountain_054', ('snowy', 'mountain')),\n",
       " ('mountain_055', ('rocky', 'mountain')),\n",
       " ('mountain_055', ('blue', 'ocean')),\n",
       " ('mountain_056', ('cloudy', 'sky')),\n",
       " ('mountain_056', ('rocky', 'mountain')),\n",
       " ('mountain_057', ('blue', 'sky')),\n",
       " ('mountain_057', ('snowy', 'mountain')),\n",
       " ('mountain_059', ('blue', 'sky')),\n",
       " ('mountain_059', ('snowy', 'mountain')),\n",
       " ('mountain_060', ('rocky', 'mountain')),\n",
       " ('mountain_060', ('overcast', 'sky')),\n",
       " ('mountain_061', ('overcast', 'sky')),\n",
       " ('mountain_061', ('snowy', 'mountain')),\n",
       " ('mountain_066', ('blue', 'sky')),\n",
       " ('mountain_066', ('snowy', 'mountain')),\n",
       " ('mountain_067', ('cloudy', 'sky')),\n",
       " ('mountain_067', ('snowy', 'mountain')),\n",
       " ('mountain_071', ('blue', 'sky')),\n",
       " ('mountain_071', ('snowy', 'mountain')),\n",
       " ('mountain_072', ('cloudy', 'sky')),\n",
       " ('mountain_072', ('snowy', 'mountain')),\n",
       " ('mountain_072', ('blue', 'ocean')),\n",
       " ('mountain_073', ('overcast', 'sky')),\n",
       " ('mountain_073', ('snowy', 'mountain')),\n",
       " ('mountain_074', ('snowy', 'mountain')),\n",
       " ('mountain_074', ('blue', 'sky')),\n",
       " ('mountain_076', ('blue', 'sky')),\n",
       " ('mountain_076', ('rocky', 'mountain')),\n",
       " ('mountain_077', ('overcast', 'sky')),\n",
       " ('mountain_077', ('snowy', 'mountain')),\n",
       " ('mountain_078', ('rocky', 'mountain')),\n",
       " ('mountain_078', ('blue', 'sky')),\n",
       " ('mountain_084', ('blue', 'sky')),\n",
       " ('mountain_084', ('snowy', 'mountain')),\n",
       " ('mountain_085', ('blue', 'sky')),\n",
       " ('mountain_085', ('rocky', 'mountain')),\n",
       " ('mountain_0871', ('blue', 'sky')),\n",
       " ('mountain_0871', ('rocky', 'mountain')),\n",
       " ('mountain_088', ('rocky', 'mountain')),\n",
       " ('mountain_088', ('blue', 'sky')),\n",
       " ('mountain_091', ('blue', 'sky')),\n",
       " ('mountain_091', ('snowy', 'mountain')),\n",
       " ('mountain_094', ('blue', 'sky')),\n",
       " ('mountain_094', ('rocky', 'mountain')),\n",
       " ('mountain_095', ('blue', 'sky')),\n",
       " ('mountain_095', ('blue', 'sky')),\n",
       " ('mountain_095', ('rocky', 'mountain')),\n",
       " ('mountain_096', ('yellow', 'field')),\n",
       " ('mountain_096', ('blue', 'sky')),\n",
       " ('mountain_097', ('rocky', 'mountain')),\n",
       " ('mountain_097', ('cloudy', 'sky')),\n",
       " ('mountain_100', ('cloudy', 'sky')),\n",
       " ('mountain_100', ('rocky', 'mountain')),\n",
       " ('mountain_106', ('cloudy', 'sky')),\n",
       " ('mountain_106', ('rocky', 'mountain')),\n",
       " ('mountain_108', ('blue', 'sky')),\n",
       " ('mountain_108', ('snowy', 'mountain')),\n",
       " ('mountain_108', ('green', 'field')),\n",
       " ('mountain_110', ('blue', 'sky')),\n",
       " ('mountain_110', ('rocky', 'mountain')),\n",
       " ('mountain_111', ('blue', 'sky')),\n",
       " ('mountain_111', ('snowy', 'mountain')),\n",
       " ('mountain_113', ('blue', 'sky')),\n",
       " ('mountain_113', ('snowy', 'mountain')),\n",
       " ('mountain_113', ('green', 'field')),\n",
       " ('mountain_116', ('overcast', 'sky')),\n",
       " ('mountain_116', ('overcast', 'sky')),\n",
       " ('mountain_116', ('rocky', 'mountain')),\n",
       " ('mountain_117', ('rocky', 'mountain')),\n",
       " ('ocean_061', ('blue', 'sky')),\n",
       " ('ocean_061', ('blue', 'ocean')),\n",
       " ('ocean_0631', ('cloudy', 'sky')),\n",
       " ('ocean_0631', ('rocky', 'mountain')),\n",
       " ('ocean_0631', ('blue', 'ocean')),\n",
       " ('ocean_065', ('dusthaze', 'sky')),\n",
       " ('ocean_065', ('rocky', 'mountain')),\n",
       " ('ocean_065', ('blue', 'ocean')),\n",
       " ('ocean_066', ('blue', 'sky')),\n",
       " ('ocean_066', ('-', 'tree')),\n",
       " ('ocean_066', ('blue', 'ocean')),\n",
       " ('ocean_068', ('blue', 'sky')),\n",
       " ('ocean_068', ('-', 'tree')),\n",
       " ('ocean_068', ('blue', 'ocean')),\n",
       " ('ocean_069', ('blue', 'sky')),\n",
       " ('ocean_069', ('rocky', 'mountain')),\n",
       " ('ocean_069', ('blue', 'ocean')),\n",
       " ('ocean_070', ('blue', 'ocean')),\n",
       " ('ocean_070', ('-', 'tree')),\n",
       " ('ocean_070', ('blue', 'sky')),\n",
       " ('ocean_075', ('cloudy', 'sky')),\n",
       " ('ocean_075', ('-', 'tree')),\n",
       " ('ocean_075', ('blue', 'ocean')),\n",
       " ('ocean_077', ('-', 'tree')),\n",
       " ('ocean_077', ('blue', 'ocean')),\n",
       " ('ocean_0771', ('dusthaze', 'sky')),\n",
       " ('ocean_0771', ('-', 'tree')),\n",
       " ('ocean_0771', ('blue', 'ocean')),\n",
       " ('ocean_078', ('rocky', 'mountain')),\n",
       " ('ocean_078', ('blue', 'ocean')),\n",
       " ('ocean_079', ('-', 'tree')),\n",
       " ('ocean_079', ('blue', 'ocean')),\n",
       " ('ocean_080', ('blue', 'sky')),\n",
       " ('ocean_080', ('blue', 'ocean')),\n",
       " ('ocean_080', ('-', 'sand')),\n",
       " ('ocean_084', ('blue', 'sky')),\n",
       " ('ocean_084', ('rocky', 'mountain')),\n",
       " ('ocean_084', ('blue', 'ocean')),\n",
       " ('opencountry_137', ('-', 'tree')),\n",
       " ('opencountry_137', ('purple', 'flower')),\n",
       " ('opencountry_138', ('cloudy', 'sky')),\n",
       " ('opencountry_138', ('pink', 'flower')),\n",
       " ('opencountry_139', ('overcast', 'sky')),\n",
       " ('opencountry_139', ('pink', 'flower')),\n",
       " ('opencountry_140', ('dusthaze', 'sky')),\n",
       " ('opencountry_140', ('-', 'tree')),\n",
       " ('opencountry_140', ('purple', 'flower')),\n",
       " ('opencountry_141', ('dusthaze', 'sky')),\n",
       " ('opencountry_141', ('pink', 'flower')),\n",
       " ('opencountry_142', ('overcast', 'sky')),\n",
       " ('opencountry_142', ('red', 'flower')),\n",
       " ('opencountry_143', ('rocky', 'mountain')),\n",
       " ('opencountry_143', ('green', 'field')),\n",
       " ('opencountry_143', ('pink', 'flower')),\n",
       " ('opencountry_144', ('-', 'tree')),\n",
       " ('opencountry_144', ('purple', 'flower')),\n",
       " ('opencountry_145', ('pink', 'flower')),\n",
       " ('opencountry_145', ('dusthaze', 'sky')),\n",
       " ('opencountry_146', ('dusthaze', 'sky')),\n",
       " ('opencountry_146', ('-', 'tree')),\n",
       " ('opencountry_146', ('purple', 'flower')),\n",
       " ('opencountry_147', ('red', 'flower')),\n",
       " ('opencountry_147', ('dusthaze', 'sky')),\n",
       " ('opencountry_148', ('overcast', 'sky')),\n",
       " ('opencountry_148', ('purple', 'flower')),\n",
       " ('opencountry_149', ('red', 'flower')),\n",
       " ('opencountry_149', ('dusthaze', 'sky')),\n",
       " ('opencountry_150', ('dusthaze', 'sky')),\n",
       " ('opencountry_150', ('-', 'sand')),\n",
       " ('opencountry_151', ('snowy', 'mountain')),\n",
       " ('opencountry_151', ('blue', 'sky')),\n",
       " ('opencountry_152', ('blue', 'sky')),\n",
       " ('opencountry_152', ('-', 'sand')),\n",
       " ('opencountry_153', ('cloudy', 'sky')),\n",
       " ('opencountry_153', ('-', 'tree')),\n",
       " ('opencountry_153', ('-', 'sand')),\n",
       " ('opencountry_154', ('blue', 'sky')),\n",
       " ('opencountry_154', ('snowy', 'field')),\n",
       " ('opencountry_157', ('overcast', 'sky')),\n",
       " ('opencountry_157', ('snowy', 'field')),\n",
       " ('opencountry_158', ('snowy', 'field')),\n",
       " ('opencountry_158', ('blue', 'sky')),\n",
       " ('opencountry_159', ('blue', 'sky')),\n",
       " ('opencountry_159', ('rocky', 'mountain')),\n",
       " ('opencountry_159', ('-', 'sand')),\n",
       " ('opencountry_162', ('blue', 'sky')),\n",
       " ('opencountry_162', ('-', 'sand')),\n",
       " ('opencountry_163', ('blue', 'sky')),\n",
       " ('opencountry_163', ('snowy', 'field')),\n",
       " ('opencountry_164', ('blue', 'sky')),\n",
       " ('opencountry_164', ('-', 'sand')),\n",
       " ('opencountry_165', ('blue', 'sky')),\n",
       " ('opencountry_165', ('-', 'sand')),\n",
       " ('opencountry_166', ('blue', 'sky')),\n",
       " ('opencountry_166', ('-', 'sand')),\n",
       " ('opencountry_167', ('blue', 'sky')),\n",
       " ('opencountry_167', ('-', 'tree')),\n",
       " ('opencountry_167', ('blue', 'ocean')),\n",
       " ('opencountry_1671', ('blue', 'sky')),\n",
       " ('opencountry_1671', ('-', 'tree')),\n",
       " ('opencountry_1671', ('-', 'sand')),\n",
       " ('opencountry_169', ('dusthaze', 'sky')),\n",
       " ('opencountry_169', ('green', 'field')),\n",
       " ('opencountry_170', ('cloudy', 'sky')),\n",
       " ('opencountry_170', ('rocky', 'mountain')),\n",
       " ('opencountry_170', ('yellow', 'field')),\n",
       " ('opencountry_171', ('blue', 'sky')),\n",
       " ('opencountry_171', ('-', 'tree')),\n",
       " ('opencountry_171', ('green', 'field')),\n",
       " ('opencountry_172', ('yellow', 'field')),\n",
       " ('opencountry_172', ('-', 'tree')),\n",
       " ('opencountry_172', ('blue', 'sky')),\n",
       " ('opencountry_1721', ('blue', 'sky')),\n",
       " ('opencountry_1721', ('blue', 'sky')),\n",
       " ('opencountry_1721', ('-', 'tree')),\n",
       " ('opencountry_1721', ('yellow', 'field')),\n",
       " ('opencountry_175', ('blue', 'sky')),\n",
       " ('opencountry_175', ('-', 'sand')),\n",
       " ('opencountry_178', ('blue', 'sky')),\n",
       " ('opencountry_178', ('snowy', 'field')),\n",
       " ('opencountry_179', ('-', 'sand')),\n",
       " ('opencountry_179', ('blue', 'sky')),\n",
       " ('opencountry_182', ('overcast', 'sky')),\n",
       " ('opencountry_182', ('overcast', 'sky')),\n",
       " ('opencountry_182', ('snowy', 'mountain')),\n",
       " ('opencountry_1821', ('overcast', 'sky')),\n",
       " ('opencountry_1821', ('snowy', 'field')),\n",
       " ('opencountry_183', ('blue', 'sky')),\n",
       " ('opencountry_183', ('snowy', 'field')),\n",
       " ('opencountry_185', ('cloudy', 'sky')),\n",
       " ('opencountry_185', ('-', 'tree')),\n",
       " ('opencountry_185', ('yellow', 'field')),\n",
       " ('opencountry_1851', ('-', 'tree')),\n",
       " ('opencountry_1851', ('yellow', 'field')),\n",
       " ('opencountry_1961', ('blue', 'sky')),\n",
       " ('opencountry_1961', ('-', 'tree')),\n",
       " ('opencountry_1961', ('snowy', 'field')),\n",
       " ('opencountry_202', ('blue', 'sky')),\n",
       " ('opencountry_202', ('snowy', 'field')),\n",
       " ('opencountry_203', ('blue', 'sky')),\n",
       " ('opencountry_203', ('snowy', 'mountain')),\n",
       " ('opencountry_206', ('blue', 'sky')),\n",
       " ('opencountry_206', ('-', 'tree')),\n",
       " ('opencountry_206', ('snowy', 'field')),\n",
       " ('opencountry_212', ('blue', 'sky')),\n",
       " ('opencountry_212', ('-', 'sand')),\n",
       " ('opencountry_214', ('blue', 'sky')),\n",
       " ('opencountry_214', ('-', 'sand')),\n",
       " ('opencountry_215', ('blue', 'sky')),\n",
       " ('opencountry_215', ('-', 'sand')),\n",
       " ('opencountry_216', ('blue', 'sky')),\n",
       " ('opencountry_216', ('snowy', 'mountain')),\n",
       " ('opencountry_217', ('blue', 'sky')),\n",
       " ('opencountry_217', ('yellow', 'field')),\n",
       " ('opencountry_218', ('-', 'tree')),\n",
       " ('opencountry_218', ('blue', 'sky')),\n",
       " ('opencountry_218', ('snowy', 'field')),\n",
       " ('opencountry_220', ('overcast', 'sky')),\n",
       " ('opencountry_220', ('-', 'sand')),\n",
       " ('opencountry_221', ('blue', 'sky')),\n",
       " ('opencountry_221', ('-', 'sand')),\n",
       " ('opencountry_222', ('blue', 'sky')),\n",
       " ('opencountry_222', ('snowy', 'field')),\n",
       " ('opencountry_223', ('blue', 'sky')),\n",
       " ('opencountry_223', ('-', 'road')),\n",
       " ('opencountry_224', ('cloudy', 'sky')),\n",
       " ('opencountry_224', ('yellow', 'field')),\n",
       " ('opencountry_225', ('blue', 'sky')),\n",
       " ('opencountry_225', ('-', 'sand')),\n",
       " ('opencountry_226', ('overcast', 'sky')),\n",
       " ('opencountry_226', ('snowy', 'mountain')),\n",
       " ('opencountry_227', ('blue', 'sky')),\n",
       " ('opencountry_227', ('yellow', 'field')),\n",
       " ('opencountry_2271', ('blue', 'sky')),\n",
       " ('opencountry_2271', ('-', 'sand')),\n",
       " ('opencountry_228', ('-', 'tree')),\n",
       " ('opencountry_228', ('green', 'field')),\n",
       " ('opencountry_231', ('blue', 'sky')),\n",
       " ('opencountry_231', ('red', 'flower')),\n",
       " ('opencountry_232', ('red', 'flower')),\n",
       " ('opencountry_232', ('green', 'field')),\n",
       " ('opencountry_232', ('blue', 'sky')),\n",
       " ('opencountry_235', ('blue', 'sky')),\n",
       " ('opencountry_235', ('rocky', 'mountain')),\n",
       " ('opencountry_235', ('snowy', 'field')),\n",
       " ('opencountry_236', ('pink', 'flower')),\n",
       " ('opencountry_236', ('rocky', 'mountain')),\n",
       " ('opencountry_236', ('blue', 'sky')),\n",
       " ('opencountry_237', ('blue', 'sky')),\n",
       " ('opencountry_237', ('-', 'tree')),\n",
       " ('opencountry_237', ('purple', 'flower')),\n",
       " ('opencountry_238', ('-', 'tree')),\n",
       " ('opencountry_238', ('blue', 'ocean')),\n",
       " ('opencountry_238', ('dusthaze', 'sky')),\n",
       " ('opencountry_239', ('red', 'flower')),\n",
       " ('opencountry_239', ('-', 'tree')),\n",
       " ('opencountry_239', ('overcast', 'sky')),\n",
       " ('opencountry_240', ('blue', 'sky')),\n",
       " ('opencountry_240', ('purple', 'flower')),\n",
       " ('opencountry_241', ('pink', 'flower')),\n",
       " ('opencountry_241', ('overcast', 'sky')),\n",
       " ('opencountry_242', ('blue', 'sky')),\n",
       " ('opencountry_242', ('-', 'tree')),\n",
       " ('opencountry_242', ('pink', 'flower')),\n",
       " ('opencountry_test_041', ('blue', 'sky')),\n",
       " ('opencountry_test_041', ('red', 'flower')),\n",
       " ('palace_001', ('dusthaze', 'sky')),\n",
       " ('palace_001', ('front', 'building')),\n",
       " ('palace_001', ('yellow', 'field')),\n",
       " ('palace_002', ('blue', 'sky')),\n",
       " ('palace_002', ('front', 'building')),\n",
       " ('palace_002', ('yellow', 'field')),\n",
       " ('palace_003', ('dusthaze', 'sky')),\n",
       " ('palace_003', ('front', 'building')),\n",
       " ('palace_003', ('green', 'field')),\n",
       " ('palace_004', ('dusthaze', 'sky')),\n",
       " ('palace_004', ('front', 'building')),\n",
       " ('palace_004', ('green', 'field')),\n",
       " ('palace_008', ('overcast', 'sky')),\n",
       " ('palace_008', ('overcast', 'sky')),\n",
       " ('palace_008', ('front', 'building')),\n",
       " ('palace_008', ('green', 'field')),\n",
       " ('palace_009', ('blue', 'sky')),\n",
       " ('palace_009', ('front', 'building')),\n",
       " ('palace_009', ('green', 'field')),\n",
       " ('palace_0091', ('blue', 'sky')),\n",
       " ('palace_0091', ('front', 'building')),\n",
       " ('palace_0091', ('green', 'field')),\n",
       " ('palace_015', ('dusthaze', 'sky')),\n",
       " ('palace_015', ('front', 'building')),\n",
       " ('palace_015', ('green', 'field')),\n",
       " ('palace_0151', ('overcast', 'sky')),\n",
       " ('palace_0151', ('front', 'building')),\n",
       " ('palace_0151', ('green', 'field')),\n",
       " ('palace_019', ('blue', 'sky')),\n",
       " ('palace_019', ('front', 'building')),\n",
       " ('palace_019', ('blue', 'ocean')),\n",
       " ('palace_023', ('overcast', 'sky')),\n",
       " ('palace_023', ('front', 'building')),\n",
       " ('palace_023', ('green', 'field')),\n",
       " ('palace_024', ('blue', 'sky')),\n",
       " ('palace_024', ('front', 'building')),\n",
       " ('palace_024', ('blue', 'ocean')),\n",
       " ('palace_025', ('dusthaze', 'sky')),\n",
       " ('palace_025', ('front', 'building')),\n",
       " ('palace_025', ('-', 'road')),\n",
       " ('palace_0261', ('blue', 'sky')),\n",
       " ('palace_0261', ('front', 'building')),\n",
       " ('palace_0261', ('green', 'field')),\n",
       " ('palace_029', ('blue', 'sky')),\n",
       " ('palace_029', ('front', 'building')),\n",
       " ('palace_029', ('blue', 'ocean')),\n",
       " ('palace_030', ('dusthaze', 'sky')),\n",
       " ('palace_030', ('front', 'building')),\n",
       " ('palace_030', ('green', 'field')),\n",
       " ('palace_0321', ('dusthaze', 'sky')),\n",
       " ('palace_0321', ('front', 'building')),\n",
       " ('palace_0321', ('yellow', 'field')),\n",
       " ('palace_0331', ('blue', 'sky')),\n",
       " ('palace_0331', ('front', 'building')),\n",
       " ('palace_0331', ('green', 'field')),\n",
       " ('palace_034', ('dusthaze', 'sky')),\n",
       " ('palace_034', ('dusthaze', 'sky')),\n",
       " ('palace_034', ('yellow', 'field')),\n",
       " ('palace_034', ('green', 'field')),\n",
       " ('palace_035', ('blue', 'sky')),\n",
       " ('palace_035', ('front', 'building')),\n",
       " ('palace_035', ('green', 'field')),\n",
       " ('palace_037', ('blue', 'sky')),\n",
       " ('palace_037', ('front', 'building')),\n",
       " ('palace_037', ('blue', 'ocean')),\n",
       " ('palace_039', ('blue', 'sky')),\n",
       " ('palace_039', ('front', 'building')),\n",
       " ('palace_039', ('green', 'field')),\n",
       " ('palace_040', ('overcast', 'sky')),\n",
       " ...]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"ground_truth/SceneAtt.txt\") as f:\n",
    "    images = []\n",
    "    fn_tags = []\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        line = line.strip('\\n')\n",
    "        if line == \"\":\n",
    "            images.append(tuple(fn_tags))\n",
    "            fn_tags = []\n",
    "            count = 0\n",
    "            continue\n",
    "        if count == 1:\n",
    "            if '-' in line:\n",
    "                line = tuple(line.split('-'))\n",
    "            else:\n",
    "                line = ('-',line)\n",
    "        if not count == 2:\n",
    "            fn_tags.append(line)\n",
    "            \n",
    "        count+=1      \n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af499c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n"
     ]
    }
   ],
   "source": [
    "adj_classes = list(set([item[1][0] for item in images]))\n",
    "noun_classes = list(set([item[1][1] for item in images]))\n",
    "\n",
    "get_itoadj = lambda i:adj_classes[i]\n",
    "get_adjtoi = lambda a:adj_classes.index(a)\n",
    "get_itonoun = lambda i:noun_classes[i]\n",
    "get_nountoi = lambda n:noun_classes.index(n)\n",
    "\n",
    "\n",
    "ANP_classes = [(adj,noun) for adj in adj_classes for noun in noun_classes]\n",
    "print(len(ANP_classes)) # => 19 adjs * 16 nouns = 304 possible ANP combinations\n",
    "\n",
    "get_itoANP = lambda i:ANP_classes[i]\n",
    "get_ANPtoi = lambda p:ANP_classes.index(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "8cabf0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>ANP_id</th>\n",
       "      <th>adj_id</th>\n",
       "      <th>noun_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[tensor(-0.5767), tensor(-0.5767), tensor(-0...</td>\n",
       "      <td>tensor(37)</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[tensor(-0.1486), tensor(-0.1486), tensor(-0...</td>\n",
       "      <td>tensor(280)</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[tensor(-0.4911), tensor(-0.4911), tensor(-0...</td>\n",
       "      <td>tensor(37)</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[tensor(-1.2274), tensor(-1.2274), tensor(-1...</td>\n",
       "      <td>tensor(37)</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[tensor(0.2453), tensor(0.2967), tensor(0.34...</td>\n",
       "      <td>tensor(69)</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>[[[tensor(1.6153), tensor(1.7009), tensor(1.68...</td>\n",
       "      <td>tensor(280)</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>[[[tensor(0.9132), tensor(0.9474), tensor(0.96...</td>\n",
       "      <td>tensor(69)</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>[[[tensor(1.4783), tensor(1.4954), tensor(1.51...</td>\n",
       "      <td>tensor(69)</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>[[[tensor(0.3481), tensor(0.4166), tensor(0.43...</td>\n",
       "      <td>tensor(1)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>[[[tensor(-1.8097), tensor(-1.5014), tensor(-1...</td>\n",
       "      <td>tensor(283)</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2656 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    img       ANP_id  adj_id  \\\n",
       "0     [[[tensor(-0.5767), tensor(-0.5767), tensor(-0...   tensor(37)       2   \n",
       "1     [[[tensor(-0.1486), tensor(-0.1486), tensor(-0...  tensor(280)      17   \n",
       "2     [[[tensor(-0.4911), tensor(-0.4911), tensor(-0...   tensor(37)       2   \n",
       "3     [[[tensor(-1.2274), tensor(-1.2274), tensor(-1...   tensor(37)       2   \n",
       "4     [[[tensor(0.2453), tensor(0.2967), tensor(0.34...   tensor(69)       4   \n",
       "...                                                 ...          ...     ...   \n",
       "2651  [[[tensor(1.6153), tensor(1.7009), tensor(1.68...  tensor(280)      17   \n",
       "2652  [[[tensor(0.9132), tensor(0.9474), tensor(0.96...   tensor(69)       4   \n",
       "2653  [[[tensor(1.4783), tensor(1.4954), tensor(1.51...   tensor(69)       4   \n",
       "2654  [[[tensor(0.3481), tensor(0.4166), tensor(0.43...    tensor(1)       0   \n",
       "2655  [[[tensor(-1.8097), tensor(-1.5014), tensor(-1...  tensor(283)      17   \n",
       "\n",
       "      noun_id  \n",
       "0           5  \n",
       "1           8  \n",
       "2           5  \n",
       "3           5  \n",
       "4           5  \n",
       "...       ...  \n",
       "2651        8  \n",
       "2652        5  \n",
       "2653        5  \n",
       "2654        1  \n",
       "2655       11  \n",
       "\n",
       "[2656 rows x 4 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "get_ANP_array = lambda ANP: torch.tensor(get_ANPtoi(ANP))\n",
    "def file_to_tensor(img_path):\n",
    "    # (PIL.Image obj) => pt tensor 3x224x224\n",
    "    # load jpg directly as tensor of CxHxW to avoid needing converting from numpy and permuting\n",
    "    preprocess_fn = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "    \n",
    "    # PIL Img obj\n",
    "    img = Image.open(img_path)\n",
    "    img_tensor = preprocess_fn(img)\n",
    "    return img_tensor\n",
    "\n",
    "import random\n",
    "def train_val_split(dataset, val_portion=0.2):\n",
    "    random.shuffle(dataset)\n",
    "    val_split = int( len(dataset) * val_portion)\n",
    "    train, val = dataset[val_split:], dataset[:val_split]\n",
    "    return train, val\n",
    "    \n",
    "dataset = [(file_to_tensor(f'Image/{fn}.jpg'), get_ANP_array(ANP), get_adjtoi(ANP[0]), get_nountoi(ANP[1])) \n",
    "           for fn, ANP in images]\n",
    "train_data, val_data = train_val_split(dataset)\n",
    "\n",
    "pd.DataFrame(train_data, columns=['img','ANP_id', 'adj_id', 'noun_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2ae4e4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "52cc78f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveAvgPool2d(output_size=(1, 1))"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(resnet.children())[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "37621c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SubNet(nn.Module):\n",
    "    '''\n",
    "    encoder module\n",
    "    - use pre-trained encoder: ResNet101 trained on ImageNet classification task\n",
    "    '''\n",
    "\n",
    "    def __init__(self, num_classes, encoded_image_size=14, hidden_size=2048, fine_tune=False):\n",
    "        super(SubNet, self).__init__()\n",
    "        self.enc_image_size = encoded_image_size # resnet out: 14 x 14\n",
    "        \n",
    "        # Exclude ResNet's last 2 layers (avgpool & fc1000) for image representations\n",
    "        resnet = torchvision.models.resnet101(pretrained=True) # Pretrained ResNet101 model\n",
    "        resnet_layers = list(resnet.children())\n",
    "        resnet_abstrations = resnet_layers[:-1]\n",
    "        \n",
    "        self.resnet = nn.Sequential(*resnet_abstrations) # Output = image abstract reps\n",
    "        \n",
    "        # fc \n",
    "        self.fc_layers = nn.Sequential(\n",
    "                                       nn.Linear(2048, num_classes),\n",
    "                                       nn.Softmax(1),\n",
    "                                      )\n",
    "        \n",
    "        # Enable finetuning\n",
    "        self.fine_tune(fine_tune=fine_tune)\n",
    "\n",
    "\n",
    "    def forward(self, images):\n",
    "        '''\n",
    "        Forward propagation.\n",
    "        :param images: images, a tensor of dimensions (batch_size, 3, image_size, image_size)\n",
    "        :return: encoded images\n",
    "        '''\n",
    "        out = self.resnet(images)  # (batch_size, 2048, image_size/32, image_size/32)\n",
    "\n",
    "        out = out.view(out.shape[0], -1) # Keep batch and flatten other dims\n",
    "        out = self.fc_layers(out)\n",
    "        return out\n",
    "\n",
    "    def fine_tune(self, fine_tune=True):\n",
    "\n",
    "        for p in self.resnet.parameters():\n",
    "            p.requires_grad = False\n",
    "        # If fine-tuning, only fine-tune convolutional blocks 2 through 4\n",
    "        for c in list(self.resnet.children())[5:]: # 3 bottleneck blocks\n",
    "            for p in c.parameters():\n",
    "                p.requires_grad = fine_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "229e2287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SubNet(epochs, train_data, val_data, batch_size, device, target_idx, num_classes, lr=0.001):\n",
    "    \n",
    "    #Batch iterator\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "    \n",
    "    m = SubNet(num_classes, fine_tune=True)\n",
    "    m.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss() # ignore y padding\n",
    "    optimizer = optim.Adam(m.parameters(), lr=lr)\n",
    "    \n",
    "    #Epoch loop\n",
    "    \n",
    "    for e in range(epochs):\n",
    "#         start_time = datetime.now()\n",
    "        # Train\n",
    "        m.train()\n",
    "        train_loss = 0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            x, y = data[0].to(device), data[target_idx].to(device)\n",
    "            \n",
    "            out = m(x)\n",
    "            \n",
    "            loss = loss_fn(out, y) \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Compute gradient and update parameters\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(f\"Epoch {e+1} avg train loss {train_loss/(i+1)}\", end='\\r')\n",
    "        print(end=\"\\t\")\n",
    "#         torch.save(m, model_fn)\n",
    "        \n",
    "        # Eval\n",
    "        m.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for i, data in enumerate(train_loader):\n",
    "                x, y = data[0].to(device), data[target_idx].to(device)\n",
    "\n",
    "                out = m(x)\n",
    "\n",
    "                loss = loss_fn(out, y) \n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                print(f\"Epoch {e+1} avg val loss {val_loss/(i+1)}\", end='\\r')\n",
    "            print()\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "c2751d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 avg val loss 2.819449972389336456\n",
      "Epoch 2 avg val loss 2.818821192684030376\n",
      "Epoch 3 avg val loss 2.809708551356667488\n",
      "Epoch 4 avg val loss 2.815643592884666613Epoch 4 avg val loss 2.9308314323425293\n",
      "Epoch 5 avg val loss 2.775810185231660667Epoch 5 avg val loss 2.6581003665924072\n",
      "Epoch 6 avg val loss 2.770032176397797444Epoch 6 avg val loss 2.9292616844177246\n",
      "Epoch 7 avg val loss 2.773491842406136897\n",
      "Epoch 8 avg val loss 2.763045155016103365\n",
      "Epoch 9 avg val loss 2.769557967221826593Epoch 9 avg val loss 2.8309099674224854\n",
      "Epoch 10 avg val loss 2.750629019020195713Epoch 10 avg val loss 2.8301072120666504\n"
     ]
    }
   ],
   "source": [
    "adj_net = train_SubNet(epochs=10, \n",
    "                       train_data=train_data, val_data=val_data, \n",
    "                       batch_size=10, device='cuda:0', \n",
    "                       target_idx=2, num_classes=19,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "9bdaaf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 avg val loss 2.540270895886242763Epoch 1 avg val loss 2.1748263835906982\n",
      "Epoch 2 avg val loss 2.511951296849358348Epoch 2 avg val loss 2.299464464187622\n",
      "Epoch 3 avg val loss 2.566043402019362427Epoch 3 avg val loss 2.3440146446228027\n",
      "Epoch 4 avg val loss 2.572706419722478324Epoch 4 avg val loss 2.6704936027526855\n",
      "Epoch 5 avg val loss 2.576112430794794743\n",
      "Epoch 6 avg val loss 2.528272915603523334\n",
      "Epoch 7 avg val loss 2.513878119619269377\n",
      "Epoch 8 avg val loss 2.513521482173661333\n",
      "Epoch 9 avg val loss 2.552891113704308426Epoch 9 avg val loss 2.306199550628662\n",
      "Epoch 10 avg val loss 2.510596774574509693\n"
     ]
    }
   ],
   "source": [
    "noun_net = train_SubNet(epochs=10, \n",
    "                       train_data=train_data, val_data=val_data, \n",
    "                       batch_size=10, device='cuda:0', \n",
    "                       target_idx=3, num_classes=16,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "4ca4b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANPNet(nn.Module):\n",
    " \n",
    " \n",
    "    def __init__(self, num_ANPs=304, num_adjs=19, num_nouns=16 ,hidden_size=1024):\n",
    "        super(ANPNet, self).__init__()\n",
    "        \n",
    "        # Sub modules\n",
    "#         self.adj_net = SubNet(num_adjs, hidden_size=hidden_size)\n",
    "#         self.noun_net = SubNet(num_adjs, hidden_size=hidden_size)\n",
    "        self.adj_net = adj_net\n",
    "        self.adj_net.fine_tune(fine_tune=False)\n",
    "        self.noun_net = noun_net\n",
    "        self.noun_net.fine_tune(fine_tune=False)\n",
    "        \n",
    "        # fuse fc \n",
    "        self.fc_layers = nn.Sequential(nn.Linear(hidden_size, 1024),\n",
    "                                       nn.ReLu(),\n",
    "                                       nn.Linear(1024, num_ANPs),\n",
    "                                       nn.Softmax(1)\n",
    "                                      )\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.lin = nn.Linear(num_adjs+num_nouns, hidden_size)\n",
    "\n",
    "\n",
    "    def forward(self, images):\n",
    "        '''\n",
    "        Forward propagation.\n",
    "        :param images: images, a tensor of dimensions (batch_size, 3, image_size, image_size)\n",
    "        :return: encoded images\n",
    "        '''\n",
    "        # representations from two resnets\n",
    "        adj_out = self.adj_net(images)\n",
    "        noun_out = self.noun_net(images)\n",
    "        \n",
    "\n",
    "        # fuse the two outputs: concat? add? multiply?\n",
    "        fused = torch.cat((adj_out,noun_out),dim=1)\n",
    "        fused = self.lin(fused)\n",
    "        out = self.fc_layers(fused)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "fb300a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 304])\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=2, shuffle=True)\n",
    "adj_model = ANPNet()\n",
    "for x,y in train_loader:\n",
    "    out = adj_model(x)\n",
    "    print(out.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "31bb6104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "\n",
    "def train(model, model_fn, epochs, train_data, val_data, batch_size, device, lr=0.005):\n",
    "    \n",
    "    #Batch iterator\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "    \n",
    "    m = model.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss() # ignore y padding\n",
    "    optimizer = optim.Adam(m.parameters(), lr=lr)\n",
    "    \n",
    "    #Epoch loop\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        start_time = datetime.now()\n",
    "        # Train\n",
    "        m.train()\n",
    "        train_loss = 0\n",
    "        for i, (x, y, _, _) in enumerate(train_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            out = m(x)\n",
    "            \n",
    "            loss = loss_fn(out, y) \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Compute gradient and update parameters\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(f\"Epoch {e+1} avg train loss {train_loss/(i+1)}\", end='\\r')\n",
    "        print()\n",
    "#         torch.save(m, model_fn)\n",
    "        \n",
    "        # Eval\n",
    "        m.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for i, (x, y, _, _) in enumerate(train_loader):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "                out = m(x)\n",
    "\n",
    "                loss = loss_fn(out, y) \n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                print(f\"Epoch {e+1} avg val loss {val_loss/(i+1)}\", end='\\r')\n",
    "            print()\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "5ff7b7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 avg train loss 5.5533749214688645\n",
      "Epoch 1 avg val loss 5.5786879223988475\n",
      "Epoch 2 avg train loss 5.5323551543673185\n",
      "Epoch 2 avg val loss 5.5263472750670935\n",
      "Epoch 3 avg train loss 5.5317226639367586\n",
      "Epoch 3 avg val loss 5.5230844361441475\n",
      "Epoch 4 avg train loss 5.5299312548529835\n",
      "Epoch 4 avg val loss 5.5228329816258945\n",
      "Epoch 5 avg train loss 5.5243811499803595\n",
      "Epoch 5 avg val loss 5.5212525281691015\n",
      "Epoch 6 avg train loss 5.5265218691718315\n",
      "Epoch 6 avg val loss 5.5214051698383535\n",
      "Epoch 7 avg train loss 5.5292115175634445\n",
      "Epoch 7 avg val loss 5.5170683466402215\n",
      "Epoch 8 avg train loss 5.5237423566947315\n",
      "Epoch 8 avg val loss 5.5195158944094095\n",
      "Epoch 9 avg train loss 5.5400457346349736\n",
      "Epoch 9 avg val loss 5.5415294260010685\n",
      "Epoch 10 avg train loss 5.5349380629403255\n",
      "Epoch 10 avg val loss 5.5559874477243065\n"
     ]
    }
   ],
   "source": [
    "init_model = ANPNet()\n",
    "\n",
    "trained_model = train(init_model, \"anp-net\", 10, \n",
    "                      train_data, val_data, batch_size=20, device='cuda:0', lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "db3afe2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1290726/571761327.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_itoANP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mmake_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Image/opencountry_240.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1290726/571761327.py\u001b[0m in \u001b[0;36mmake_pred\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# feed tensor thru model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margmax_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# argmax of logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mconfidences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1290726/408721558.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     30\u001b[0m         '''\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# representations from two resnets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0madj_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mnoun_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoun_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1290726/3237511993.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencoded\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         '''\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, 2048, image_size/32, image_size/32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Keep batch and flatten other dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 439\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def make_pred(img_path):\n",
    "    \n",
    "    trained_model.eval()\n",
    "    \n",
    "    # (PIL.Image obj) => pt tensor 3x224x224\n",
    "    # load jpg directly as tensor of CxHxW to avoid needing converting from numpy and permuting\n",
    "    preprocess_fn = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "    \n",
    "    # PIL Img obj\n",
    "    img = Image.open(img_path)\n",
    "    img_tensor = preprocess_fn(img)\n",
    "    batch_tensor = img_tensor.unsqueeze(0)\n",
    "    \n",
    "    # feed tensor thru model\n",
    "    output = trained_model(batch_tensor)\n",
    "    _, argmax_index = torch.max(output,dim=1) # argmax of logits\n",
    "    confidences = torch.nn.functional.softmax(output, dim=1)[0] *100\n",
    "    \n",
    "    # 304 classes to predict\n",
    "    pred = argmax_index.item() # prediction\n",
    "    return get_itoANP(pred), confidences[pred].item()\n",
    "\n",
    "make_pred(f\"Image/opencountry_240.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "d4707a73",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (torch.Size, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!torch.Size!, !Parameter!, !NoneType!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!torch.Size!, !Parameter!, !NoneType!, !tuple!, !tuple!, !tuple!, int)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1290726/2042794710.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoun_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1290726/3237511993.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencoded\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         '''\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, 2048, image_size/32, image_size/32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Keep batch and flatten other dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 439\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (torch.Size, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!torch.Size!, !Parameter!, !NoneType!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!torch.Size!, !Parameter!, !NoneType!, !tuple!, !tuple!, !tuple!, int)\n"
     ]
    }
   ],
   "source": [
    "for x, _ in val_loader:\n",
    "    print(noun_net(x.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63c7f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Milti-output classification (A+N)\n",
    "#TODO\n",
    "# 1) load data from ImageNet --> x:img, y:[(A,N),...]\n",
    "# see distr of A and N ---> only choose imgs with frequent A and N (>100?)\n",
    "\n",
    "# 2) ANet, NNet --> ResNet, fc n_classes and sigmoid; train with BCELoss(threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c5b98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "    #     resnet = models.resnext50_32x4d(pretrained=True)\n",
    "        resnet = torchvision.models.resnet101(pretrained=True) # Pretrained ResNet101 model\n",
    "        resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=resnet.fc.in_features, out_features=n_classes)\n",
    "        )\n",
    "\n",
    "        self.base_model = resnet\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigm(self.base_model(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
